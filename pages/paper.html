<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Papers - OpenData</title>
    <link href="../css/global.css" rel="stylesheet">
    <link href="../css/pages/paper.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</head>
<body>
    <div class="container">
        <!-- Load template first -->
        <div data-include="/components/paper-card.html"></div>

        <!-- HEADER -->
        <div data-include="/components/header.html"></div>

        <!-- Overlay -->
        <div id="overlay" class="overlay"></div>
        
        <!-- Sidebar -->
        <div data-include="/components/slidebar.html"></div>

        <!-- Main Content -->
        <div class="main-content">
            <h1 class="search-title">Research Papers</h1>
            <p class="subtitle">Discover, analyze and share cutting-edge research across all areas of machine learning and AI.</p>
            
            <!-- Action Buttons -->
            <div class="action-buttons">
                <a href="../upload/upload-paper.html" class="action-button upload">
                    <i class="fas fa-upload"></i>
                    Upload Paper
                </a>
                <a href="#" class="action-button your-papers">
                    <i class="fas fa-file-alt"></i>
                    Your Papers
                </a>
            </div>

            <!-- Search Bar -->
            <div class="search-big paper-search">
                <i class="fas fa-search search-icon"></i>
                <input type="text" placeholder="Search Papers, Authors, or Conferences">
                <button class="filter-button">
                    <i class="fas fa-filter"></i>
                    Filters
                </button>
            </div>
        </div>

        <!-- Research Areas Tabs -->
        <div class="area-tabs">
            <button class="area-tab active" data-area="all">All Areas</button>
            <button class="area-tab" data-area="computer-vision">Computer Vision</button>
            <button class="area-tab" data-area="nlp">Natural Language Processing</button>
            <button class="area-tab" data-area="reinforcement-learning">Reinforcement Learning</button>
            <button class="area-tab" data-area="generative-ai">Generative AI</button>
            <button class="area-tab" data-area="more">
                <i class="fas fa-ellipsis-h"></i>
            </button>
        </div>

        <!-- Paper List -->
        <div class="papers-container">
            <!-- Computer Vision Papers -->
            <div class="area-section" id="computer-vision">
                <h2 class="area-title">Computer Vision <span class="paper-count">124 papers</span></h2>
                
                <div class="papers-grid">
                    <!-- Paper 1 -->
                    <div class="paper-card">
                        <div class="paper-header">
                            <div class="paper-meta">
                                <span class="conference">CVPR 2023</span>
                                <span class="date">June 2023</span>
                            </div>
                            <div class="paper-badges">
                                <span class="badge code-badge"><i class="fas fa-code"></i> Code</span>
                                <span class="badge dataset-badge"><i class="fas fa-database"></i> Dataset</span>
                            </div>
                        </div>
                        <h3 class="paper-title">Vision Transformer for Enhanced Image Recognition</h3>
                        <p class="paper-authors">Anh Nguyen, Minh Tran, Binh Le, Huong Pham</p>
                        <p class="paper-abstract">
                            This paper introduces a novel vision transformer architecture that improves image recognition accuracy by 5.7% on standard benchmarks while reducing computational requirements by 30%.
                        </p>
                        <div class="paper-footer">
                            <div class="paper-metrics">
                                <span class="metric"><i class="fas fa-star"></i> 257</span>
                                <span class="metric"><i class="fas fa-quote-right"></i> 43</span>
                            </div>
                            <div class="paper-links">
                                <a href="#" class="paper-link"><i class="fas fa-external-link-alt"></i> Paper</a>
                                <a href="#" class="paper-link"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                    </div>

                    <!-- Paper 2 -->
                    <div class="paper-card">
                        <div class="paper-header">
                            <div class="paper-meta">
                                <span class="conference">ICCV 2023</span>
                                <span class="date">October 2023</span>
                            </div>
                            <div class="paper-badges">
                                <span class="badge code-badge"><i class="fas fa-code"></i> Code</span>
                            </div>
                        </div>
                        <h3 class="paper-title">Multi-Modal Scene Understanding with Contrastive Learning</h3>
                        <p class="paper-authors">Linh Vo, Trang Nguyen, Quang Pham</p>
                        <p class="paper-abstract">
                            We propose a contrastive learning approach that integrates visual, depth, and semantic information for improved scene understanding in autonomous driving scenarios.
                        </p>
                        <div class="paper-footer">
                            <div class="paper-metrics">
                                <span class="metric"><i class="fas fa-star"></i> 183</span>
                                <span class="metric"><i class="fas fa-quote-right"></i> 21</span>
                            </div>
                            <div class="paper-links">
                                <a href="#" class="paper-link"><i class="fas fa-external-link-alt"></i> Paper</a>
                                <a href="#" class="paper-link"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                    </div>
                </div>
                
                <button class="load-more-button">
                    Load More Papers <i class="fas fa-chevron-down"></i>
                </button>
            </div>

            <!-- Natural Language Processing Papers -->
            <div class="area-section" id="nlp">
                <h2 class="area-title">Natural Language Processing <span class="paper-count">98 papers</span></h2>
                
                <div class="papers-grid">
                    <!-- Paper 1 -->
                    <div class="paper-card">
                        <div class="paper-header">
                            <div class="paper-meta">
                                <span class="conference">ACL 2023</span>
                                <span class="date">July 2023</span>
                            </div>
                            <div class="paper-badges">
                                <span class="badge code-badge"><i class="fas fa-code"></i> Code</span>
                                <span class="badge dataset-badge"><i class="fas fa-database"></i> Dataset</span>
                                <span class="badge benchmark-badge"><i class="fas fa-chart-line"></i> Benchmark</span>
                            </div>
                        </div>
                        <h3 class="paper-title">Vietnamese-specific Pretraining for Enhanced NLP Performance</h3>
                        <p class="paper-authors">Thanh Nguyen, Lan Tran, Huy Pham, Mai Le</p>
                        <p class="paper-abstract">
                            This paper introduces a Vietnamese-specific pretraining approach for language models, improving performance across multiple NLP tasks by an average of 6.3% compared to multilingual models.
                        </p>
                        <div class="paper-footer">
                            <div class="paper-metrics">
                                <span class="metric"><i class="fas fa-star"></i> 342</span>
                                <span class="metric"><i class="fas fa-quote-right"></i> 87</span>
                            </div>
                            <div class="paper-links">
                                <a href="#" class="paper-link"><i class="fas fa-external-link-alt"></i> Paper</a>
                                <a href="#" class="paper-link"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                    </div>

                    <!-- Paper 2 -->
                    <div class="paper-card">
                        <div class="paper-header">
                            <div class="paper-meta">
                                <span class="conference">EMNLP 2023</span>
                                <span class="date">December 2023</span>
                            </div>
                            <div class="paper-badges">
                                <span class="badge code-badge"><i class="fas fa-code"></i> Code</span>
                            </div>
                        </div>
                        <h3 class="paper-title">Low-Resource Machine Translation for Southeast Asian Languages</h3>
                        <p class="paper-authors">Minh Nguyen, Tuan Tran, Anh Phan</p>
                        <p class="paper-abstract">
                            We present a transfer learning approach for machine translation in low-resource Southeast Asian languages, achieving state-of-the-art results with minimal parallel data.
                        </p>
                        <div class="paper-footer">
                            <div class="paper-metrics">
                                <span class="metric"><i class="fas fa-star"></i> 156</span>
                                <span class="metric"><i class="fas fa-quote-right"></i> 19</span>
                            </div>
                            <div class="paper-links">
                                <a href="#" class="paper-link"><i class="fas fa-external-link-alt"></i> Paper</a>
                                <a href="#" class="paper-link"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                    </div>
                </div>
                
                <button class="load-more-button">
                    Load More Papers <i class="fas fa-chevron-down"></i>
                </button>
            </div>
        </div>

                <!-- Help Button -->
                <button class="help-button">
                    <i class="fas fa-question"></i>
                </button>

                <!-- Include Help Center Popup -->
                <div data-include="/components/help-center-popup.html"></div>
    </div>

    <script src="../js/include.js"></script>
    <script src="../js/paper.js"></script>
    <script src="../js/header-dropdown.js"></script>
    <script src="../js/help-center.js"></script>
</body>
</html>